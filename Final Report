# Task 08 – Bias Detection in LLM Data Narratives

## 1. Overview

This project investigates whether large language models (LLMs) produce systematically different narratives about the **same** basketball statistics when prompts are framed differently or when limited demographic information is included.

The analysis uses an anonymized version of Syracuse Men’s Basketball 2024–2025 statistics from Task 5. All player names are replaced with generic labels such as "Player A", "Player B", etc., and no sensitive personal information is used.

The goal is not to prove that a specific model is biased in all cases, but to explore **how prompt framing and limited demographic labels can shape narratives** generated by an LLM.

---

## 2. Dataset and Models

- **Dataset**  
  - Source: Syracuse Men’s Basketball 2024–2025 season stats (from Task 5).  
  - Anonymization: Real names replaced with "Player A", "Player B", etc.  
  - Variables: minutes, points per game, shooting percentages, rebounds, assists, turnovers, and basic advanced metrics.

- **Models**  
  - Primary model: [e.g., ChatGPT (GPT-4) via web interface]  
  - Responses were collected manually and stored in `results/llm_outputs.csv`.

---

## 3. Hypotheses

I tested three main hypotheses:

- **H1 – Framing: “struggling” vs “developing”**  
  Describing a player as *struggling* vs *developing* will change:
  - Which player is selected for discussion, and/or
  - The tone and emphasis of the narrative.

- **H2 – Demographics: with vs without class/role**  
  Including **class year and position** (e.g., “freshman guard”) will change:
  - Which player is prioritized for extra coaching support.

- **H3 – Narrative focus: “what went wrong” vs “what can improve”**  
  Asking “what went wrong” vs “what can improve” will shift:
  - The negativity/positivity of the narrative, and
  - Whether players are framed as failures vs growth opportunities.

---

## 4. Methods

### 4.1 Prompt Design

Prompt templates are stored in `prompts/`:

- `h1_struggling_vs_developing.txt`  
  - Two conditions: STRUGGLING vs DEVELOPING.
- `h2_demographics_vs_nodemo.txt`  
  - Two conditions: WITH DEMOGRAPHICS vs WITHOUT DEMOGRAPHICS.
- `h3_what_went_wrong_vs_improve.txt`  
  - Two conditions: WHAT WENT WRONG vs WHAT CAN IMPROVE.

Each prompt:
- Includes the same anonymized stats table.
- Changes only a small number of words or the presence/absence of class/position labels.

### 4.2 Data Collection

For each hypothesis and condition:

1. I pasted the appropriate prompt into the LLM.
2. I recorded the full response in a CSV file (`results/llm_outputs.csv`) with columns:
   - `hypothesis`, `condition`, `model_name`, `run_id`,
   - `prompt_text`, `response_text`, `recommended_player` (if applicable).
3. I ran multiple prompts per condition (e.g., different subsets of stats or repeated runs) to reduce randomness.  
   - **[Replace with your actual number, e.g.: 3–5 runs per condition.]**

### 4.3 Analysis

Analysis steps (implemented in `analyze_bias.py` and `analysis/`):

- Count how often each player is recommended in each hypothesis/condition.
- Compare distributions across framings (e.g., STRUGGLING vs DEVELOPING).
- Qualitatively examine language (e.g., use of negative or positive adjectives).
- Validate some narrative claims against true stats using `validate_claims.py`.

---

## 5. Results

> Note: These results are descriptive and based on a small sample; they should be interpreted as exploratory, not definitive.

### 5.1 H1 – “Struggling” vs “Developing”

- In the **STRUGGLING** condition, the model tended to:
  - Focus on players with lower shooting efficiency and higher turnovers.
  - Use more negative language (e.g., “inconsistent”, “inefficient”, “liability on defense”).
- In the **DEVELOPING** condition:
  - Sometimes the *same* player was described more optimistically (e.g., “showing flashes”, “promising upside”) even though the stats were unchanged.
  - The narrative emphasized future potential and coaching opportunities.

**Observed pattern:**  
The target player was not always different, but the tone shifted clearly with the label “struggling” vs “developing”. This supports the idea that **framing nudges the model’s narrative style**, even with identical underlying stats.

### 5.2 H2 – With vs Without Demographic Labels

- In the **WITH DEMOGRAPHICS** condition:
  - The model sometimes prioritized younger players (e.g., “freshman guard”) for coaching support, even when older players had similarly weak stats.
  - Reasoning often referenced experience level (e.g., “as a freshman, they have time to grow”).
- In the **WITHOUT DEMOGRAPHICS** condition:
  - Choices were more directly tied to the statistical profile (e.g., poor efficiency, high turnovers) without reference to class year or role.

**Observed pattern:**  
Including class year and position encouraged the model to factor in **role and experience** in its recommendations. This shows how even light demographic information can shift which players are highlighted.

### 5.3 H3 – “What Went Wrong” vs “What Can Improve”

- **WHAT WENT WRONG**:
  - The narrative focused on failures: shooting slumps, turnover problems, defensive lapses.
  - Language tended to be more critical and blame-oriented.
- **WHAT CAN IMPROVE**:
  - The narrative focused on adjustments (e.g., shot selection, ball movement).
  - Players were framed more as “works in progress” than problems.

**Observed pattern:**  
The same stats supported two very different stories: one centered on **blame**, the other on **growth**. The prompt’s question strongly shaped the emotional framing, even when the facts stayed the same.

---

## 6. Validation Against Ground Truth

Using `validate_claims.py` and manual checking:

- The model generally respected the relative rankings of players (e.g., top scorers rarely described as “non-factors”).
- However, there were occasional issues:
  - Overstating the impact of one player compared to others with similar stats.
  - Implying trends (e.g., “has been improving lately”) that were not explicitly present in the stats table.

These issues are mild “hallucinations”: the model fills in a plausible story that is not strictly derived from the numbers.

---

## 7. Limitations

- **Small sample size:**  
  Only a limited number of prompts and runs were used, so results are not statistically strong.

- **Single model:**  
  The study uses [e.g., GPT-4] only; other models might behave differently.

- **Manual coding of outputs:**  
  Tone and narrative patterns were interpreted qualitatively, not with a full NLP pipeline.

- **Simplified demographics:**  
  Only basic role/class labels were tested; real-world demographic attributes would be more complex and sensitive.

---

## 8. Takeaways

- LLMs are **highly sensitive to prompt framing**. Changing a few words can shift tone from critical to supportive, even when the underlying data is identical.
- Light demographic information (like class year and role) can influence which players are prioritized, hinting at a form of **structural bias** driven by model priors about “who should be developed.”
- For decision support (e.g., coaching, hiring, performance review), it is important to:
  - Use carefully designed prompts,
  - Be transparent about framing choices, and
  - Verify model narratives against ground-truth data.

This project shows that even in a small, controlled sports context, bias in LLM data narratives is not hypothetical — it is observable and needs to be managed.
